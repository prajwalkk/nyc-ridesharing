{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0a0326998f42f45cdf4fa07683a4c17a5d1586f4c5cfcf7cdaf4ddb7918bb174f",
   "display_name": "Python 3.8.8 64-bit ('nyc_rideshare': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# This is the Final build for the Project\n",
    "\n",
    "### There are 3 main stages in this Project and one auxiliary stage which is run to set up the project. \n",
    "First, the `final_project.ipynb` is run to populate the PostGresDB and do some data cleaning. \n",
    "Later this file is run.  \n",
    "\n",
    "This file contains 3 phases:\n",
    "Data Generation -> Graph Building -> Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## Stage 1: Data Generation\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Danger:</b> Run Stage 0 before starting this\n",
    "</div>\n",
    "\n",
    "### Input: \n",
    "* Start time ``(2019-01-01 00:00:00)``\n",
    "* End time ``(2019-01-01 23:59:59)``\n",
    "* Poolsize ``(300, 420, 600)``\n",
    "    \n",
    "### Output: \n",
    "* CSV / Pandas DF that contains data for the next cycle\n",
    "    * The dataframe will contain these fields: \n",
    "         1. id\n",
    "         2. tpep_pickup_datetime\n",
    "         3. tpep_dropoff_datetime\n",
    "         4. passenger_count\n",
    "         5. trip_distance - acquired from OSRM\n",
    "         6. PULocationID\n",
    "         7. DOLocationID\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import psycopg2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Constants\n",
    "interval_dict = {\n",
    "    \"1hour\": \"\"\"1 HOURS\"\"\",\n",
    "    \"1day\": \"\"\"1 DAYS\"\"\",\n",
    "    \"1month\": \"\"\"1 MONTHS\"\"\"\n",
    "\n",
    "}\n",
    "pool_size = 300\n",
    "day_in_seconds = 24 * 3600\n",
    "\n",
    "\n",
    "# Connect to DB\n",
    "\n",
    "conn_string = \"postgresql://nycrideshare:nycrideshare@127.0.0.1:5432/nyc_taxi\"\n",
    "nyc_database = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(start_time, data_size_duration):\n",
    "    '''\n",
    "    This function aims to get a chunk of data for a month or day. Depending on the need.\n",
    "\n",
    "    [start_time]: datetime object\n",
    "    [data_size_duration]: one of the values specified in the interval_dict \n",
    "\n",
    "    '''\n",
    "    \n",
    "    time_string = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    query = \\\n",
    "        f\"\"\"select \n",
    "        id, \n",
    "        tpep_pickup_datetime, \n",
    "        tpep_dropoff_datetime, \n",
    "        passenger_count, \n",
    "        \"PULocationID\", \n",
    "        \"DOLocationID\"\n",
    "        from nyc_taxi_schema.get_cust_between_timestamps_lgd('{start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}', '{interval_dict[data_size_duration]}');\"\"\"\n",
    "\n",
    "\n",
    "    # Get the adjacency matrix\n",
    "    interzonal_dist = pd.read_csv(\"./data/interzonal.csv\")\n",
    "    # Get the dataframe\n",
    "    df_temp = pd.read_sql_query(query, nyc_database)\n",
    "    # Add the distance to all the the rows\n",
    "    df_temp[\"Distance\"] = df_temp.apply(lambda row: interzonal_dist.iloc[row[\"PULocationID\"]-1, row[\"DOLocationID\"]-1], axis=1)\n",
    "\n",
    "    return df_temp.set_index(\"id\", drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime(2019, 1,1, 00, 00,00)\n",
    "end_time = start_time + timedelta(minutes=60)\n",
    "data_size_duration = \"1hour\" # This is to get the initial dataframe\n",
    "df_generated = generate_data(start_time, data_size_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgd_flag = {\n",
    "    \"pickup\": 'PULocationID',\n",
    "    \"drop\": 'DOLocationID'\n",
    "} # this flag represents if the pickup is at LGD or Dropoff\n",
    "\n",
    "def date_iterator(ts_start, ts_end, delta_in_minutes, flag):\n",
    "    current = ts_start\n",
    "    delta = timedelta(minutes=delta_in_minutes)\n",
    "    while current < ts_end:\n",
    "        yield df_generated[\n",
    "            (df_generated['tpep_pickup_datetime'] >= current) & \n",
    "            (df_generated['tpep_pickup_datetime'] < current + delta) &\n",
    "            (df_generated[lgd_flag[flag]] == 138)]\n",
    "\n",
    "        current += delta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                  \n11866  2019-01-01 00:04:29   2019-01-01 00:26:02                1   \n\n       PULocationID  DOLocationID  Distance  \nid                                           \n11866           164           138   13397.4  \n     tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                 \n9596  2019-01-01 00:18:09   2019-01-01 00:41:11                1   \n\n      PULocationID  DOLocationID  Distance  \nid                                          \n9596           161           138   12556.8  \n    tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  PULocationID  \\\nid                                                                              \n261  2019-01-01 00:27:06   2019-01-01 00:51:51                1            68   \n\n     DOLocationID  Distance  \nid                           \n261           138   15110.6  \n      tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                  \n12778  2019-01-01 00:38:05   2019-01-01 01:14:38                1   \n\n       PULocationID  DOLocationID  Distance  \nid                                           \n12778            68           138   15110.6  \n      tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                  \n37707  2019-01-01 00:48:38   2019-01-01 01:27:28                2   \n\n       PULocationID  DOLocationID  Distance  \nid                                           \n37707           164           138   13397.4  \nEmpty DataFrame\nColumns: [tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, PULocationID, DOLocationID, Distance]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "# Just a demo for drop\n",
    "for df_filtered in date_iterator(start_time, end_time, 10, \"drop\"):\n",
    "    print(df_filtered.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                 \n5915  2019-01-01 00:02:51   2019-01-01 00:08:51                1   \n2455  2019-01-01 00:06:09   2019-01-01 00:29:46                2   \n\n      PULocationID  DOLocationID  Distance  \nid                                          \n5915           138            79   15242.4  \n2455           138           170   13219.5  \n      tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                  \n7296   2019-01-01 00:10:33   2019-01-01 00:26:52                1   \n11210  2019-01-01 00:13:38   2019-01-01 00:28:45                1   \n\n       PULocationID  DOLocationID  Distance  \nid                                           \n7296            138           236   12901.0  \n11210           138           140   12094.6  \n     tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                 \n5096  2019-01-01 00:21:07   2019-01-01 00:36:26                1   \n7697  2019-01-01 00:22:34   2019-01-01 00:36:02                1   \n\n      PULocationID  DOLocationID  Distance  \nid                                          \n5096           138           112   10588.4  \n7697           138           263   12709.8  \n     tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                 \n1336  2019-01-01 00:30:04   2019-01-01 00:48:03                1   \n1291  2019-01-01 00:30:45   2019-01-01 00:40:55                1   \n\n      PULocationID  DOLocationID  Distance  \nid                                          \n1336           138           244   15482.5  \n1291           138            95    8799.1  \n     tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                 \n7782  2019-01-01 00:40:18   2019-01-01 00:59:44                1   \n8064  2019-01-01 00:40:44   2019-01-01 00:47:53                2   \n\n      PULocationID  DOLocationID  Distance  \nid                                          \n7782           138            49   15071.8  \n8064           138           260    5719.8  \n     tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\nid                                                                 \n9487  2019-01-01 00:51:31   2019-01-01 01:20:09                1   \n\n      PULocationID  DOLocationID  Distance  \nid                                          \n9487           138            62   17961.5  \n"
     ]
    }
   ],
   "source": [
    "# Just a demo for pickup\n",
    "for df_filtered in date_iterator(start_time, end_time, 10, \"pickup\"):\n",
    "    print(df_filtered.head(2))"
   ]
  },
  {
   "source": [
    "## Stage 2: Graph Construction\n",
    "\n",
    "This stage is responsible to construct graphs using networX to model the relationships between passengers. \n",
    "The connected edges represent the rides that are merged. \n",
    "\n",
    "### Input Parameters: \n",
    "* Poolsize\n",
    "* Weight calculating functions as arguments\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Stage 3: Visualization\n",
    "\n",
    "This stage is responsible to gather data from stage to for Visualization\n",
    "\n",
    "The idea for this phase is, Phase2 at each iteration calls this method. Parameters are TBD. \n",
    "When this function is called, the merged data and individual data is collated and stored as a DF/File. This can be used later to build graphs. \n",
    "\n",
    "### Input Parameters: \n",
    "* TBD\n",
    "* TBD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}