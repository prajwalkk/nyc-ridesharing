{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0a0326998f42f45cdf4fa07683a4c17a5d1586f4c5cfcf7cdaf4ddb7918bb174f",
   "display_name": "Python 3.8.8 64-bit ('nyc_rideshare': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# This is the Final build for the Project\n",
    "\n",
    "### There are 3 main stages in this Project and one auxiliary stage which is run to set up the project. \n",
    "First, the `final_project.ipynb` is run to populate the PostGresDB and do some data cleaning. \n",
    "Later this file is run.  \n",
    "\n",
    "This file contains 3 phases:\n",
    "Data Generation -> Graph Building -> Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## Stage 1: Data Generation\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Danger:</b> Run Stage 0 before starting this\n",
    "</div>\n",
    "\n",
    "### Input: \n",
    "* Start time ``(2019-01-01 00:00:00)``\n",
    "* End time ``(2019-01-01 23:59:59)``\n",
    "* Poolsize ``(300, 420, 600)``\n",
    "    \n",
    "### Output: \n",
    "* CSV / Pandas DF that contains data for the next cycle\n",
    "    * The dataframe will contain these fields: \n",
    "         1. id\n",
    "         2. tpep_pickup_datetime\n",
    "         3. tpep_dropoff_datetime\n",
    "         4. passenger_count\n",
    "         5. trip_distance - acquired from OSRM\n",
    "         6. PULocationID\n",
    "         7. DOLocationID\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import psycopg2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Constants\n",
    "interval_dict = {\n",
    "    \"1hour\": \"\"\"1 HOURS\"\"\",\n",
    "    \"1day\": \"\"\"1 DAYS\"\"\",\n",
    "    \"1month\": \"\"\"1 MONTHS\"\"\"\n",
    "\n",
    "}\n",
    "pool_size = 300\n",
    "day_in_seconds = 24 * 3600\n",
    "\n",
    "\n",
    "# Connect to DB\n",
    "\n",
    "conn_string = \"postgresql://nycrideshare:nycrideshare@127.0.0.1:5432/nyc_taxi\"\n",
    "nyc_database = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(start_time, data_size_duration):\n",
    "    '''\n",
    "    This function aims to get a chunk of data for a month or day. Depending on the need.\n",
    "\n",
    "    [start_time]: datetime object\n",
    "    [data_size_duration]: one of the values specified in the interval_dict \n",
    "\n",
    "    '''\n",
    "    \n",
    "    time_string = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    query = \\\n",
    "        f\"\"\"select \n",
    "        id, \n",
    "        tpep_pickup_datetime, \n",
    "        tpep_dropoff_datetime, \n",
    "        passenger_count, \n",
    "        \"PULocationID\", \n",
    "        \"DOLocationID\"\n",
    "        from nyc_taxi_schema.get_cust_between_timestamps_lgd('{start_time.strftime(\"%Y-%m-%d %H:%M:%S\")}', '{interval_dict[data_size_duration]}');\"\"\"\n",
    "    df_temp = pd.read_sql_query(query, nyc_database)\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime(2019, 1,1, 00, 00,00)\n",
    "data_size_duration = \"1hour\"\n",
    "df_jan = generate_data(start_time, data_size_duration)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.458480834960938\n1239726\n"
     ]
    }
   ],
   "source": []
  },
  {
   "source": [
    "## Stage 2: Graph Construction\n",
    "\n",
    "This stage is responsible to construct graphs using networX to model the relationships between passengers. \n",
    "The connected edges represent the rides that are merged. \n",
    "\n",
    "### Input Parameters: \n",
    "* Poolsize\n",
    "* Weight calculating functions as arguments\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Stage 3: Visualization\n",
    "\n",
    "This stage is responsible to gather data from stage to for Visualization\n",
    "\n",
    "### Input Parameters: \n",
    "* TBD\n",
    "* TBD"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}